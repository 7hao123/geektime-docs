你好，我是邢云阳。

通过前面两节课，我们借助Dify熟悉了平台化开发的基础知识。

这节课，我们就进入项目实现环节。那在这一章呢，我为你准备的项目是“作业帮”。准备这个项目的初衷，是考虑了三点。

第一点是项目的通俗性，“作业帮”是干啥的，大家被广告洗脑了这么多年，对此一定不陌生，类似的还有“猿辅导”，选择这样的一个项目，很容易就能理解需求，并上手开发，不至于被一些所谓“隔行如隔山”的门槛拦在门外。

![图片](https://static001.geekbang.org/resource/image/8f/cf/8ffb79cb33fbf4c3e6aa229725c809cf.png?wh=771x926)

第二点是这两年各家的大模型都在“卷”数学题，通过解数学题的能力，来证明自己家的模型，推理能力强。因此我们可以用这个项目来体验一下这种推理能力。

第三点是多模态模型的发展，我们除了语言大模型的应用，对于视觉模型等多模态模型或者是 OCR 技术等，也需要掌握，才能在开发项目时更加游刃有余。而“作业帮”的一个主要功能就是可以给试卷拍照，识别题目后进行解答。于是综合这三点，我设计了这个项目。

今天我们就先从视觉技术开始了解。

## OCR 识别

在视觉大模型没出来以前，比较传统的 OCR 技术是如何识别图片内容的呢？这项技术虽然我说了“传统”二字，但并不过时。如果你经常使用 RAG 的话，应该会接触过，比如对 PDF 文档的识别，就会用到 OCR 技术。接下来，我就为大家演示一下 OCR 的手法。

### 开通 OCR 服务

要使用 OCR 技术，我们需要先开通 OCR 服务，这里我选择的是腾讯云的 OCR，链接是：[腾讯云 - 控制台](https://console.cloud.tencent.com/ocr/overview)。腾讯云的 OCR首次使用是有一定量的免费额度的。

![图片](https://static001.geekbang.org/resource/image/5e/be/5e189de731644a2d05fa8077fa95b1be.png?wh=1268x620)

之后，你还需要点右上角的头像，点击访问管理去创建密钥。

![图片](https://static001.geekbang.org/resource/image/d4/94/d42f5d5e572ce9ed1517af4665431394.png?wh=533x706)

### 编码

服务开通后，就可以调用腾讯的 SDK 编写代码，调用 OCR 服务了。SDK 的文档在这：[GitHub - TencentCloud/tencentcloud-sdk-python: Tencent Cloud API 3.0 SDK for Python](https://github.com/TencentCloud/tencentcloud-sdk-python)。我们需要根据文档先把 SDK 装上。执行命令：

```plain
pip install --upgrade tencentcloud-sdk-python-ocr
```

之后就可以让 Cursor 帮我们生成代码了，prompt 是：

```plain
请使用tencentcloud-sdk-python-ocr 帮我完成图片识别成文字的代码
```

之后 Cursor 会生成如下代码：

```plain
from tencentcloud.common import credential
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.ocr.v20181119 import ocr_client, models

def recognize_text(image_path):
    try:
        # 实例化认证对象
        cred = credential.Credential("SecretID", "SecretKey")
        
        # 实例化http选项
        httpProfile = HttpProfile()
        httpProfile.endpoint = "ocr.tencentcloudapi.com"

        # 实例化client选项
        clientProfile = ClientProfile()
        clientProfile.httpProfile = httpProfile

        # 实例化OCR client对象
        client = ocr_client.OcrClient(cred, "ap-guangzhou", clientProfile)

        # 读取图片文件并转为Base64
        with open(image_path, 'rb') as f:
            image = f.read()
        import base64
        image_base64 = base64.b64encode(image).decode()

        # 实例化请求对象
        req = models.GeneralBasicOCRRequest()
        req.ImageBase64 = image_base64

        # 发起OCR识别请求
        resp = client.GeneralBasicOCR(req)
        
        # 提取识别结果
        result = []
        for text_item in resp.TextDetections:
            result.append(text_item.DetectedText)
            
        return '\n'.join(result)

    except Exception as e:
        print(f"OCR识别发生错误: {str(e)}")
        return None
```

我们只需要把第 9 行的 SecretID 和 SecretKey 替换成我们自己的密钥即可。

这个代码的原理没必要深究，就是将本地图片编码成 Base64 格式后，塞给 OCR 的接口，仅此而已。接下来，我们可以写一个 main 函数测试一下：

```plain
if __name__ == "__main__":
    image_path = "试题1.png"
    result = recognize_text(image_path)
    print(result)
```

这里，我准备了一张中学数学题的图片，图片我也传到了 [GitHub](https://github.com/xingyunyang01/Geek02/tree/main/class21) 上，我们让 OCR 去识别一下。

![图片](https://static001.geekbang.org/resource/image/db/ff/db722cf8117e16ef8ff5fea7b69d2cff.png?wh=684x164)

识别效果如下所示：

![图片](https://static001.geekbang.org/resource/image/11/85/11128550c57354cfc12e6ed076ceef85.png?wh=1530x221)

可以看到，识别的效果不错。

## 视觉模型

接下来，我们再来看 AI 时代的新方法，也就是视觉模型。

所谓视觉模型，就是能识别图片中的内容的模型。如果说之前的大语言模型是大脑的话，视觉模型就是比大脑又多了双眼睛。国内的视觉模型也有很多家提供，个人认为做的水平比较高的是火山引擎的豆包大模型。因为抖音、西瓜视频等平台和火山引擎同属一家母公司，他们在训练视觉模型方面天然就有优势。

### 注册火山引擎，开通豆包大模型权限

豆包大模型是火山引擎提供的。火山引擎和我们平时使 DeepSeek 等模型提供商时，直接获取一个 API Key 就能访问大模型不同，其是以云产品的形式提供的，因此注册还有点麻烦。那么接下来，我就以一个新用户的角度，为你演示一下如何注册火山引擎。

首先访问[火山引擎官网](https://www.volcengine.com/)注册账户。

![图片](https://static001.geekbang.org/resource/image/3f/0d/3f11de4d033f5ffbea287e8f45e0000d.png?wh=1908x729)

注册完成后，点击导航栏上方的大模型，选择视觉理解模型。

![图片](https://static001.geekbang.org/resource/image/d3/15/d36ae7a0ff6fff5b7609e55yy0bd4815.png?wh=1920x606)

这时就会跳转到 Doubao-vision-pro-32k 模型，这就是我们要用到的视觉模型。那知道模型用哪款以后，我们就可以创建 API Key，在 Dify 中去调用它了。

点击右上角的头像，然后点击 API 访问密钥，会跳转到密钥管理的页面。

![图片](https://static001.geekbang.org/resource/image/a1/85/a1ee81a913afb7a85fd274d05914dc85.png?wh=469x752)

点击新建密钥进行创建即可。

![图片](https://static001.geekbang.org/resource/image/87/3f/874e183348e5c9byya94534714829a3f.png?wh=1611x302)

### 在 Dify 添加豆包大模型

完成密钥创建后，我们就可以在 Dify 中添加豆包大模型了。点击右上角头像，然后点击设置。

![图片](https://static001.geekbang.org/resource/image/14/52/14e32c5776d3d74yy4c358ca98b08a52.png?wh=336x336)

选择模型供应商，会有一个叫 Volcengine 的模型提供商，这就是火山引擎。

![图片](https://static001.geekbang.org/resource/image/8e/14/8ec3a6bd439f37a902yy65c55a63f914.png?wh=939x186)

点击添加模型，选择 LLM，模型名称随便起，我就叫豆包大模型。然后把刚才在火山引擎官网创建的 Access Key ID 和 Secret Access Key 粘贴过来。

![图片](https://static001.geekbang.org/resource/image/0a/f5/0a58f9c03684394fb400928e138e10f5.png?wh=765x613)

接下来是配置 Endpoint ID 以及基础模型。

![图片](https://static001.geekbang.org/resource/image/70/11/70dc77845763e9aeb39541acc671ff11.png?wh=727x431)

我们看火山引擎的[文档](https://www.volcengine.com/docs/82379/1362913)，可以看到 Endpoint ID 就是推理接入点。

![图片](https://static001.geekbang.org/resource/image/c5/26/c516472204ca91dcdd0fb3e96a1d1726.png?wh=1276x354)

我们点击蓝色字体[创建推理接入点](https://www.volcengine.com/docs/82379/1099522)，会进入到另一篇文档，其中有一部分叫前提条件，我们需要找到后点击蓝色字体的开通管理。

![图片](https://static001.geekbang.org/resource/image/d2/54/d2005fbfdbf10656eab068ceebcc1054.png?wh=799x195)

之后就会跳到控制台。

![图片](https://static001.geekbang.org/resource/image/47/21/4775fcc08abc14240630135c2469d221.png?wh=1884x830)

我们在大语言模型中找到 Doubao-vision-pro-32k，点击后面的开通服务，进行开通即可。

![图片](https://static001.geekbang.org/resource/image/01/f3/016a109910c9df18999f644b333265f3.png?wh=1720x652)

完成开通后，我们回到控制台，点击左侧侧边栏的在线推理。然后点击创建推理接入点。

![图片](https://static001.geekbang.org/resource/image/a5/28/a5ba0c372d8bfc5ae1b00a1948069628.png?wh=1393x888)

在弹出的页面中选择好 Doubao-vision-pro-32k 模型，点击确认接入。

![图片](https://static001.geekbang.org/resource/image/e3/08/e33d6b671078050cc969c187c2197908.png?wh=1846x782)

之后就会跳转到这个模型的在线推理页面。红框内的 ID 就是接入点 ID。

![图片](https://static001.geekbang.org/resource/image/90/98/9071604c8a6fb9d733af2d889bb3f798.png?wh=465x107)

我们将其粘贴到 Dify 的 Endpoint ID 处，然后基础模型选择 Doubao-vision-pro-32k 即可。

![图片](https://static001.geekbang.org/resource/image/96/c7/96e07472da39234871aef9a9212c81c7.png?wh=737x332)

## 搭建“作业帮”工作流

模型添加好之后，我们就可以搭建“作业帮”项目的工作流了。

### 图片识别

我们在Dify选择创建空白应用，类型选工作流。

![图片](https://static001.geekbang.org/resource/image/13/82/13f34245e6e7b83c41796dc4384c0682.png?wh=864x812)

随后在开始节点，点击输入字段的加号。

![图片](https://static001.geekbang.org/resource/image/18/b4/18a3a59805fdcd832952595b1b35a3b4.png?wh=897x618)

之后变量选择单文件，支持的文件类型选图片，上传文件类型选择本地上传。

![图片](https://static001.geekbang.org/resource/image/c6/ba/c6da6c22d3d8bf46e0d42b1b05930dba.png?wh=502x884)

接下来，我们在开始节点后添加一个 LLM 节点。

![图片](https://static001.geekbang.org/resource/image/ec/a3/ec79a73d86ac31da9368e0d36e9cffa3.png?wh=1112x681)

模型选择豆包大模型，然后编写 SYSTEM 和 User 提示词：

```plain
SYSTEM
你是一个图片文字识别助手

USER
识别图片上的文字并输出，不要做任何的解释和说明
```

最后将节点的视觉按钮的开关打开，变量选择开始节点定义的 Questions 变量。

然后我们就可以添加一个结束节点，测试图片识别了。

![图片](https://static001.geekbang.org/resource/image/98/6e/98c3899713714a2a7fc24e59cefe816e.png?wh=1381x448)

注意结束节点要设置 LLM 节点的输出 text。

我还是用那道数学题的图片，可以点击运行测试一下识别效果。

![图片](https://static001.geekbang.org/resource/image/c1/a1/c17bfc90b514ed2f301923e970facaa1.png?wh=684x164)

点击从本地上传，然后开始运行。

![图片](https://static001.geekbang.org/resource/image/e2/3a/e2135b22b5f04e5c122abee9562b4c3a.png?wh=429x323)

这时就发现运行到 LLM 节点时报错了。

![图片](https://static001.geekbang.org/resource/image/29/72/290dac59afcd1a5931de417c3d653c72.png?wh=1539x566)

具体错误信息是：

```plain
[volcengine_maas] Error: PluginInvokeError: {"args":{},"error_type":"ValidationError","message":"1 validation error for ModelInvokeLLMRequest\nprompt_messages.content.type\n Input should be \u003cPromptMessageContentType.TEXT: 'text'\u003e [type=literal_error, input_value='text', input_type=str]\n For further information visit https://errors.pydantic.dev/2.8/v/literal_error"}
```

这是因为 Dify 调用的最新版本的火山引擎 SDK，在 prompt\_messages.content.type 里不能填字符串类型的 text 了，而应该填 PromptMessageContentType.TEXT，因此报错。想要解决这个问题，我们就需要对 Dify 的火山引擎插件做降版本操作。

点击插件，选择火山方舟，将红框中的 0.0.9 切换为 0.0.7。

![图片](https://static001.geekbang.org/resource/image/2c/9e/2cb2ff38283154b4fbff4b4e905ac89e.png?wh=1908x580)

然后再回到工作流，重新运行一下，就会发现问题解决了。

![图片](https://static001.geekbang.org/resource/image/64/34/6490e1c8a0e631629b8d7449d910f934.png?wh=435x254)

### 试题分析解答

图片识别测试通过后，我们就可以把提示词修改一下，让豆包大模型将图片内容解析出来后，直接进行分析解答了。

提示词如下：

```plain
SYSTEM
你是一个初中数学老师

USER
请识别出图片中的试题内容，并进行计算解答。输出格式为：
题目：识别出的题目内容
答案：题目的答案
解析：对于题目每一问的解析
```

然后再次运行，会得到如下所示的回答结果。

```plain
题目：观察下列单项式 -2x，4x²， -8x³，16x⁴， -32x⁵，64x⁶，…
(1) 分别指出单项式的系数和指数是怎样变化的？
(2) 写出第10个单项式；
(3) 写出第n个单项式。

答案：
(1) 系数的绝对值依次是2，4，8，16，32，64…，后一项是前一项的2倍，且奇数项为负，偶数项为正；指数依次是1，2，3，4，5，6…，与项数相同。
(2) 第10个单项式为1024x¹⁰。
(3) 第n个单项式为(-2)ⁿxⁿ。

解析：
(1) 对于系数，第一项是-2，第二项是4 = (-2)×(-2)，第三项是-8 = 4×(-2)，以此类推，系数的绝对值后一项是前一项的2倍，且奇数项为负，偶数项为正；对于指数，第一项是x的1次方，第二项是x的2次方，第三项是x的3次方，依次类推，指数与项数相同。
(2) 根据前面分析的规律，第10项的系数为(-2)¹⁰=1024，指数为10，所以第10个单项式为1024x¹⁰。
(3) 综合系数和指数的规律，可得第n个单项式为(-2)ⁿxⁿ。 
```

看起来豆包大模型的数学能力还可以，解决一下中学的数学题问题不大。今天的测试图片我已经上传到了 [Github](https://github.com/xingyunyang01/Geek02/tree/main/class21)，你可以下载后进行自测。

## 总结

今天这节课，我们一起学习了两种识别图片文字的方法，一种是使用视觉大模型，比如豆包 AI；另一种则是使用 OCR 技术进行识别。在 RAG 中进行表格、PDF 等类型识别的场景里，这种技术非常常用。

之后，我们初步搭建了“作业帮”工作流，让豆包 AI 识别试题图片内容后，进行了计算解答，实际测试下来效果不错。但“作业帮”发展了这么多年，如果我们仅凭一个视觉模型就实现了其功能，那是完全不可能的。因为 AI 答题肯定会有答错的时候。

而“作业帮”能保持很高的正确率，离不开它的题库。因此在下一节课，我会用 RAG 技术模拟题库功能，提高我们这个项目的答题正确率。

## 思考题

为什么视觉模型出来后，OCR 技术没有被淘汰呢？你认为这两者分别适用于什么场景？

欢迎你在留言区展示你的思考结果，我们一起探讨。如果你觉得这节课的内容对你有帮助的话，也欢迎你分享给其他朋友，我们下节课再见！
<div><strong>精选留言（7）</strong></div><ul>
<li><span>jogholy</span> 👍（1） 💬（1）<p>老师，一般都去哪里找到全球最新大模型的对比情况？那种一张图可以看明白的。</p>2025-04-17</li><br/><li><span>西钾钾</span> 👍（1） 💬（1）<p>在特定领域OCR技术还是具备优势。比如字牌识别，准确率、速度以及成本都具有优势。</p>2025-04-16</li><br/><li><span>momo</span> 👍（0） 💬（1）<p>老师，现在最新火山方舟0.0.14版本没有图片报错了</p>2025-05-26</li><br/><li><span>Jim</span> 👍（0） 💬（1）<p>单纯使用图片上传视觉模型还是没有一个闭环的，项目中也使用了4o识别，但是总是差那么一点，但是结合本地快速OCR，拿到参考文字再结合视觉模型，准确率一下子提高很多</p>2025-04-27</li><br/><li><span>ifelse</span> 👍（0） 💬（1）<p>学习打卡</p>2025-04-21</li><br/><li><span>bearkang</span> 👍（0） 💬（1）<p>请问一下，这个场景常常题目中有图片，这种大模型怎么处理呢？他不认识图片</p>2025-04-18</li><br/><li><span>悟空聊架构</span> 👍（0） 💬（0）<p>ocr小巧精悍</p>2025-05-27</li><br/>
</ul>